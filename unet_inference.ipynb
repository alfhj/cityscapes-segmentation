{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unet_model import *\n",
    "from glob import glob\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from torchvision import transforms\n",
    "from datetime import datetime\n",
    "from collections import namedtuple\n",
    "import numpy as np\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "train_path = glob('data/leftImg8bit/train/*/*leftImg8bit.png')\n",
    "val_path = glob('data/leftImg8bit/val/*/*leftImg8bit.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "GroupedLabel = namedtuple(\"GroupedLabel\", [\n",
    "    \"id\", # group id\n",
    "    \"name\", # group name\n",
    "    \"ids\", # list of ids\n",
    "    \"color\", # color of the group\n",
    "])\n",
    "grouped_labels = [\n",
    "    GroupedLabel(0, \"motor vehicles\" , [26, 27, 28, 28, 29, 30, 31, 32],           (  0,   0, 142)),\n",
    "    GroupedLabel(1, \"pedestrians\"    , [24, 25, 33],                               (220,  20,  60)),\n",
    "    GroupedLabel(2, \"road\"           , [6, 7, 8, 9, 10],                           (128,  64, 128)),\n",
    "    GroupedLabel(3, \"traffic objects\", [17, 18, 19, 20],                           (250, 170,  30)),\n",
    "    GroupedLabel(4, \"background\"     , [4, 5, 11, 12, 13, 14, 15, 16, 21, 22, 23], ( 70,  70,  70)),\n",
    "    GroupedLabel(5, \"void\"           , [0, 2, 3],                                  (  0,   0,   0)),\n",
    "    GroupedLabel(6, \"ego vehicle\"    , [1],                                        (  0,   0,   0)),\n",
    "]\n",
    "\n",
    "def classes_to_rgb(output: torch.Tensor) -> torch.Tensor:\n",
    "    # Input: (num_classes, H, W)\n",
    "    # Output: (3, H, W)\n",
    "    rgb = torch.zeros((3, *output.size()[-2:]))\n",
    "    output_max = torch.argmax(output.squeeze(), dim=0)\n",
    "    for label in grouped_labels:\n",
    "        for c in range(3):\n",
    "            rgb[c][output_max == label.id] = label.color[c] / 255\n",
    "    return rgb\n",
    "\n",
    "def gt_to_classes(gt: np.ndarray) -> torch.Tensor:\n",
    "    # Input: (H, W), values: 0-num_classes\n",
    "    # Output: (num_classes, H, W)\n",
    "    output = torch.zeros((len(grouped_labels), *gt.shape))\n",
    "    for group in grouped_labels:\n",
    "        output[group.id] = torch.Tensor(np.isin(gt, group.ids))\n",
    "    return output\n",
    "\n",
    "def infer(unet_model, img_path, out_path):\n",
    "    label_path = img_path.replace(\"leftImg8bit\", \"gtFine\").replace(\".png\", \"_labelIds.png\")\n",
    "    img = np.array(Image.open(img_path))\n",
    "    label = np.array(Image.open(label_path))\n",
    "    h, w = img.shape[:2]\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize((h//4, w//4), antialias=True),\n",
    "        #transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.2),\n",
    "    ])\n",
    "    transform1 = transforms.Compose([\n",
    "        transforms.Resize((h//4, w//4), antialias=True),\n",
    "    ])\n",
    "\n",
    "    img_in = transform(img).to(device)[None]\n",
    "    label_in = transform1(gt_to_classes(label)).to(device)[None]\n",
    "    output = unet_model(img_in)\n",
    "    output = classes_to_rgb(output)\n",
    "    label_in = classes_to_rgb(label_in)\n",
    "    output = output.cpu().detach().numpy().transpose(1, 2, 0).clip(0, 1)\n",
    "    img_in = img_in.cpu().detach()[0].numpy().transpose(1, 2, 0)\n",
    "    label_in = label_in.cpu().detach().numpy().transpose(1, 2, 0)\n",
    "    \n",
    "    plt.imsave(out_path, output)\n",
    "    return img_in, output, label_in\n",
    "    # fig, ax = plt.subplots(1, 3, figsize=(20, 5))\n",
    "    # ax[0].imshow(img_in)\n",
    "    # ax[1].imshow(output)\n",
    "    # ax[2].imshow(label)\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving weights\\unetsegment_231126_171755_checkpoint_0.pt output\n",
      "Saving weights\\unetsegment_231126_171755_checkpoint_1.pt output\n",
      "Saving weights\\unetsegment_231126_171755_checkpoint_2.pt output\n",
      "Saving weights\\unetsegment_231126_171755_checkpoint_3.pt output\n",
      "Saving weights\\unetsegment_231126_171755_checkpoint_4.pt output\n",
      "Saving weights\\unetsegment_231126_171755_checkpoint_5.pt output\n",
      "Saving weights\\unetsegment_231126_171755_checkpoint_6.pt output\n",
      "Saving weights\\unetsegment_231126_171755_checkpoint_7.pt output\n",
      "Saving weights\\unetsegment_231126_171755_checkpoint_8.pt output\n",
      "Saving weights\\unetsegment_231126_171755_checkpoint_9.pt output\n",
      "Saving weights\\unetsegment_231126_171755_checkpoint_10.pt output\n",
      "Saving weights\\unetsegment_231126_171755_checkpoint_11.pt output\n",
      "Saving weights\\unetsegment_231126_171755_checkpoint_12.pt output\n",
      "Saving weights\\unetsegment_231126_171755_checkpoint_13.pt output\n",
      "Saving weights\\unetsegment_231126_171755_checkpoint_14.pt output\n",
      "Saving weights\\unetsegment_231126_171755_checkpoint_15.pt output\n",
      "Saving weights\\unetsegment_231126_171755_checkpoint_16.pt output\n",
      "Saving weights\\unetsegment_231126_171755_checkpoint_17.pt output\n",
      "Saving weights\\unetsegment_231126_171755_checkpoint_18.pt output\n",
      "Saving weights\\unetsegment_231126_171755_checkpoint_19.pt output\n",
      "Saving weights\\unetsegment_231126_171755_checkpoint_20.pt output\n",
      "Saving weights\\unetsegment_231126_171755_checkpoint_21.pt output\n",
      "Saving weights\\unetsegment_231126_171755_checkpoint_22.pt output\n",
      "Saving weights\\unetsegment_231126_171755_checkpoint_23.pt output\n",
      "Saving weights\\unetsegment_231126_171755_checkpoint_24.pt output\n",
      "Saving weights\\unetsegment_231126_171755_checkpoint_25.pt output\n",
      "Saving weights\\unetsegment_231126_171755_checkpoint_26.pt output\n",
      "Saving weights\\unetsegment_231126_171755_checkpoint_27.pt output\n",
      "Saving weights\\unetsegment_231126_171755_checkpoint_28.pt output\n",
      "Saving weights\\unetsegment_231126_171755_checkpoint_29.pt output\n",
      "Saving weights\\unetsegment_231126_171755_checkpoint_30.pt output\n",
      "Saving weights\\unetsegment_231126_171755_checkpoint_31.pt output\n",
      "Saving weights\\unetsegment_231126_171755_checkpoint_32.pt output\n",
      "Saving weights\\unetsegment_231126_171755_checkpoint_33.pt output\n",
      "Saving weights\\unetsegment_231126_171755_checkpoint_34.pt output\n",
      "Saving weights\\unetsegment_231126_171755_checkpoint_35.pt output\n",
      "Saving weights\\unetsegment_231126_171755_checkpoint_36.pt output\n",
      "Saving weights\\unetsegment_231126_171755_checkpoint_37.pt output\n",
      "Saving weights\\unetsegment_231126_171755_checkpoint_38.pt output\n",
      "Saving weights\\unetsegment_231126_171755_checkpoint_39.pt output\n",
      "Saving weights\\unetsegment_231126_171755_checkpoint_40.pt output\n",
      "Saving weights\\unetsegment_231126_171755_checkpoint_41.pt output\n",
      "Saving weights\\unetsegment_231126_171755_checkpoint_42.pt output\n",
      "Saving weights\\unetsegment_231126_171755_checkpoint_43.pt output\n",
      "Saving weights\\unetsegment_231126_171755_checkpoint_44.pt output\n",
      "Saving weights\\unetsegment_231126_171755_checkpoint_45.pt output\n",
      "Saving weights\\unetsegment_231126_171755_checkpoint_46.pt output\n",
      "Saving weights\\unetsegment_231126_171755_checkpoint_47.pt output\n",
      "Saving weights\\unetsegment_231126_171755_checkpoint_48.pt output\n",
      "Saving weights\\unetsegment_231126_171755_checkpoint_49.pt output\n"
     ]
    }
   ],
   "source": [
    "models = Path(\"weights\").glob(\"unetsegment_231126_171755_checkpoint_*.pt\")\n",
    "models = sorted(models, key=lambda x: int(x.name.split(\"_\")[-1].split(\".\")[0]))\n",
    "img = random.choice(val_path)\n",
    "for model in models:\n",
    "    print(f\"Saving {model} output\")\n",
    "    unet_model = UNet(3, 7).float().to(device)\n",
    "    checkpoint = torch.load(model)\n",
    "    unet_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    _, _, label = infer(unet_model, img, f\"output/{model.stem}.png\")\n",
    "plt.imsave(f\"output/{model.stem}_gt.png\", label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 6.1-full_build-www.gyan.dev Copyright (c) 2000-2023 the FFmpeg developers\n",
      "  built with gcc 12.2.0 (Rev10, Built by MSYS2 project)\n",
      "  configuration: --enable-gpl --enable-version3 --enable-static --pkg-config=pkgconf --disable-w32threads --disable-autodetect --enable-fontconfig --enable-iconv --enable-gnutls --enable-libxml2 --enable-gmp --enable-bzlib --enable-lzma --enable-libsnappy --enable-zlib --enable-librist --enable-libsrt --enable-libssh --enable-libzmq --enable-avisynth --enable-libbluray --enable-libcaca --enable-sdl2 --enable-libaribb24 --enable-libaribcaption --enable-libdav1d --enable-libdavs2 --enable-libuavs3d --enable-libzvbi --enable-librav1e --enable-libsvtav1 --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxavs2 --enable-libxvid --enable-libaom --enable-libjxl --enable-libopenjpeg --enable-libvpx --enable-mediafoundation --enable-libass --enable-frei0r --enable-libfreetype --enable-libfribidi --enable-libharfbuzz --enable-liblensfun --enable-libvidstab --enable-libvmaf --enable-libzimg --enable-amf --enable-cuda-llvm --enable-cuvid --enable-ffnvcodec --enable-nvdec --enable-nvenc --enable-dxva2 --enable-d3d11va --enable-libvpl --enable-libshaderc --enable-vulkan --enable-libplacebo --enable-opencl --enable-libcdio --enable-libgme --enable-libmodplug --enable-libopenmpt --enable-libopencore-amrwb --enable-libmp3lame --enable-libshine --enable-libtheora --enable-libtwolame --enable-libvo-amrwbenc --enable-libcodec2 --enable-libilbc --enable-libgsm --enable-libopencore-amrnb --enable-libopus --enable-libspeex --enable-libvorbis --enable-ladspa --enable-libbs2b --enable-libflite --enable-libmysofa --enable-librubberband --enable-libsoxr --enable-chromaprint\n",
      "  libavutil      58. 29.100 / 58. 29.100\n",
      "  libavcodec     60. 31.102 / 60. 31.102\n",
      "  libavformat    60. 16.100 / 60. 16.100\n",
      "  libavdevice    60.  3.100 / 60.  3.100\n",
      "  libavfilter     9. 12.100 /  9. 12.100\n",
      "  libswscale      7.  5.100 /  7.  5.100\n",
      "  libswresample   4. 12.100 /  4. 12.100\n",
      "  libpostproc    57.  3.100 / 57.  3.100\n",
      "Input #0, image2, from 'output/unetsegment_231126_171755_checkpoint_%d.png':\n",
      "  Duration: 00:00:10.00, start: 0.000000, bitrate: N/A\n",
      "  Stream #0:0: Video: png, rgba(pc, gbr/unknown/unknown), 512x256 [SAR 3937:3937 DAR 2:1], 5 fps, 5 tbr, 5 tbn\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (png (native) -> h264 (libx264))\n",
      "Press [q] to stop, [?] for help\n",
      "[libx264 @ 0000021bbb29d500] using SAR=1/1\n",
      "[libx264 @ 0000021bbb29d500] using cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
      "[libx264 @ 0000021bbb29d500] profile High, level 4.0, 4:2:0, 8-bit\n",
      "[libx264 @ 0000021bbb29d500] 264 - core 164 r3161 a354f11 - H.264/MPEG-4 AVC codec - Copyleft 2003-2023 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=0.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=0 threads=18 lookahead_threads=3 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=5 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=13.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to 'output/video_231126_204721.mp4':\n",
      "  Metadata:\n",
      "    encoder         : Lavf60.16.100\n",
      "  Stream #0:0: Video: h264 (avc1 / 0x31637661), yuv420p(tv, progressive), 2048x1024 [SAR 1:1 DAR 2:1], q=2-31, 5 fps, 10240 tbn\n",
      "    Metadata:\n",
      "      encoder         : Lavc60.31.102 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: N/A\n",
      "frame=    0 fps=0.0 q=0.0 size=       0kB time=N/A bitrate=N/A speed=N/A    \n",
      "frame=    0 fps=0.0 q=0.0 size=       0kB time=N/A bitrate=N/A speed=N/A    \n",
      "[out#0/mp4 @ 0000021bbb29e9c0] video:660kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.216013%\n",
      "frame=   50 fps=0.0 q=-1.0 Lsize=     661kB time=00:00:09.40 bitrate= 576.5kbits/s speed=9.83x    \n",
      "[libx264 @ 0000021bbb29d500] frame I:1     Avg QP: 0.85  size: 22010\n",
      "[libx264 @ 0000021bbb29d500] frame P:15    Avg QP: 8.25  size: 17816\n",
      "[libx264 @ 0000021bbb29d500] frame B:34    Avg QP:10.73  size: 11352\n",
      "[libx264 @ 0000021bbb29d500] consecutive B-frames:  4.0% 12.0% 12.0% 72.0%\n",
      "[libx264 @ 0000021bbb29d500] mb I  I16..4: 93.7%  0.0%  6.2%\n",
      "[libx264 @ 0000021bbb29d500] mb P  I16..4:  5.8%  0.7%  2.0%  P16..4:  7.6%  1.9%  0.9%  0.0%  0.0%    skip:81.1%\n",
      "[libx264 @ 0000021bbb29d500] mb B  I16..4:  0.6%  0.0%  0.7%  B16..8:  6.8%  1.9%  0.6%  direct: 1.4%  skip:88.1%  L0:53.9% L1:45.4% BI: 0.8%\n",
      "[libx264 @ 0000021bbb29d500] 8x8 transform intra:3.8% inter:1.4%\n",
      "[libx264 @ 0000021bbb29d500] coded y,uvDC,uvAC intra: 9.5% 25.4% 24.7% inter: 0.9% 3.8% 3.8%\n",
      "[libx264 @ 0000021bbb29d500] i16 v,h,dc,p: 88% 11%  1%  0%\n",
      "[libx264 @ 0000021bbb29d500] i8 v,h,dc,ddl,ddr,vr,hd,vl,hu:  6%  6% 87%  1%  0%  0%  0%  0%  0%\n",
      "[libx264 @ 0000021bbb29d500] i4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 31% 22% 34%  3%  2%  2%  2%  2%  2%\n",
      "[libx264 @ 0000021bbb29d500] i8c dc,h,v,p: 74% 14% 11%  1%\n",
      "[libx264 @ 0000021bbb29d500] Weighted P-Frames: Y:0.0% UV:0.0%\n",
      "[libx264 @ 0000021bbb29d500] ref P L0: 69.6%  0.5% 19.7% 10.1%\n",
      "[libx264 @ 0000021bbb29d500] ref B L0: 71.7% 22.5%  5.9%\n",
      "[libx264 @ 0000021bbb29d500] ref B L1: 89.3% 10.7%\n",
      "[libx264 @ 0000021bbb29d500] kb/s:540.16\n"
     ]
    }
   ],
   "source": [
    "! ffmpeg -y -f image2 -framerate 5 -i \"output/unetsegment_231126_171755_checkpoint_%d.png\" -c:v libx264 -vf hqx=4 -pix_fmt yuv420p -crf 13 -x264-params psy-rd=0 output/video_{datetime.now().strftime(r\"%y%m%d_%H%M%S\")}.mp4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
