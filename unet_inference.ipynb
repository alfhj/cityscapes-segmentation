{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unet_model import *\n",
    "from glob import glob\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from torchvision import transforms\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "train_path = glob('data/leftImg8bit/train/*/*leftImg8bit.png')\n",
    "val_path = glob('data/leftImg8bit/val/*/*leftImg8bit.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(unet_model, img_path, out_path):\n",
    "    label_path = img_path.replace(\"leftImg8bit\", \"gtFine\").replace(\".png\", \"_color.png\")\n",
    "    img = plt.imread(img_path)\n",
    "    label = plt.imread(label_path)[:, :, :3]\n",
    "    h, w = img.shape[:2]\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize((h//2, w//2), antialias=True),\n",
    "        #transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.2),\n",
    "    ])\n",
    "\n",
    "    img_in = transform(img).to(device)[None]\n",
    "    label_in = transform(label).to(device)[None]\n",
    "    output = unet_model(img_in).cpu().detach()[0].numpy().transpose(1, 2, 0).clip(0, 1)\n",
    "    img_in = img_in.cpu().detach()[0].numpy().transpose(1, 2, 0)\n",
    "    label_in = label_in.cpu().detach()[0].numpy().transpose(1, 2, 0)\n",
    "    \n",
    "    plt.imsave(out_path, output)\n",
    "    return img_in, output, label_in\n",
    "    # fig, ax = plt.subplots(1, 3, figsize=(20, 5))\n",
    "    # ax[0].imshow(img_in)\n",
    "    # ax[1].imshow(output)\n",
    "    # ax[2].imshow(label)\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving weights\\unetsegment_checkpoint_0.pt output\n",
      "Saving weights\\unetsegment_checkpoint_1.pt output\n",
      "Saving weights\\unetsegment_checkpoint_10.pt output\n",
      "Saving weights\\unetsegment_checkpoint_11.pt output\n",
      "Saving weights\\unetsegment_checkpoint_12.pt output\n",
      "Saving weights\\unetsegment_checkpoint_13.pt output\n",
      "Saving weights\\unetsegment_checkpoint_14.pt output\n",
      "Saving weights\\unetsegment_checkpoint_15.pt output\n",
      "Saving weights\\unetsegment_checkpoint_16.pt output\n",
      "Saving weights\\unetsegment_checkpoint_17.pt output\n",
      "Saving weights\\unetsegment_checkpoint_18.pt output\n",
      "Saving weights\\unetsegment_checkpoint_19.pt output\n",
      "Saving weights\\unetsegment_checkpoint_2.pt output\n",
      "Saving weights\\unetsegment_checkpoint_20.pt output\n",
      "Saving weights\\unetsegment_checkpoint_21.pt output\n",
      "Saving weights\\unetsegment_checkpoint_22.pt output\n",
      "Saving weights\\unetsegment_checkpoint_23.pt output\n",
      "Saving weights\\unetsegment_checkpoint_24.pt output\n",
      "Saving weights\\unetsegment_checkpoint_25.pt output\n",
      "Saving weights\\unetsegment_checkpoint_26.pt output\n",
      "Saving weights\\unetsegment_checkpoint_27.pt output\n",
      "Saving weights\\unetsegment_checkpoint_28.pt output\n",
      "Saving weights\\unetsegment_checkpoint_29.pt output\n",
      "Saving weights\\unetsegment_checkpoint_3.pt output\n",
      "Saving weights\\unetsegment_checkpoint_30.pt output\n",
      "Saving weights\\unetsegment_checkpoint_31.pt output\n",
      "Saving weights\\unetsegment_checkpoint_32.pt output\n",
      "Saving weights\\unetsegment_checkpoint_33.pt output\n",
      "Saving weights\\unetsegment_checkpoint_34.pt output\n",
      "Saving weights\\unetsegment_checkpoint_35.pt output\n",
      "Saving weights\\unetsegment_checkpoint_36.pt output\n",
      "Saving weights\\unetsegment_checkpoint_37.pt output\n",
      "Saving weights\\unetsegment_checkpoint_38.pt output\n",
      "Saving weights\\unetsegment_checkpoint_39.pt output\n",
      "Saving weights\\unetsegment_checkpoint_4.pt output\n",
      "Saving weights\\unetsegment_checkpoint_40.pt output\n",
      "Saving weights\\unetsegment_checkpoint_41.pt output\n",
      "Saving weights\\unetsegment_checkpoint_42.pt output\n",
      "Saving weights\\unetsegment_checkpoint_43.pt output\n",
      "Saving weights\\unetsegment_checkpoint_44.pt output\n",
      "Saving weights\\unetsegment_checkpoint_45.pt output\n",
      "Saving weights\\unetsegment_checkpoint_46.pt output\n",
      "Saving weights\\unetsegment_checkpoint_47.pt output\n",
      "Saving weights\\unetsegment_checkpoint_48.pt output\n",
      "Saving weights\\unetsegment_checkpoint_49.pt output\n",
      "Saving weights\\unetsegment_checkpoint_5.pt output\n",
      "Saving weights\\unetsegment_checkpoint_6.pt output\n",
      "Saving weights\\unetsegment_checkpoint_7.pt output\n",
      "Saving weights\\unetsegment_checkpoint_8.pt output\n",
      "Saving weights\\unetsegment_checkpoint_9.pt output\n",
      "Saving weights\\unetsegment_final.pt output\n"
     ]
    }
   ],
   "source": [
    "models = Path(\"weights\").glob(\"unetsegment_*.pt\")\n",
    "img = random.choice(val_path)\n",
    "for model in models:\n",
    "    print(f\"Saving {model} output\")\n",
    "    unet_model = UNet(3, 3).float().to(device)\n",
    "    checkpoint = torch.load(model)\n",
    "    unet_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    _, _, label = infer(unet_model, img, f\"output/{model.stem}.png\")\n",
    "plt.imsave(f\"output/{model.stem}_gt.png\", label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.2.3 Copyright (c) 2000-2020 the FFmpeg developers\n",
      "  built with gcc 9.3.1 (GCC) 20200523\n",
      "  configuration: --enable-gpl --enable-version3 --enable-sdl2 --enable-fontconfig --enable-gnutls --enable-iconv --enable-libass --enable-libdav1d --enable-libbluray --enable-libfreetype --enable-libmp3lame --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libopus --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libtheora --enable-libtwolame --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libzimg --enable-lzma --enable-zlib --enable-gmp --enable-libvidstab --enable-libvorbis --enable-libvo-amrwbenc --enable-libmysofa --enable-libspeex --enable-libxvid --enable-libaom --enable-libmfx --enable-amf --enable-ffnvcodec --enable-cuvid --enable-d3d11va --enable-nvenc --enable-nvdec --enable-dxva2 --enable-avisynth --enable-libopenmpt\n",
      "  libavutil      56. 31.100 / 56. 31.100\n",
      "  libavcodec     58. 54.100 / 58. 54.100\n",
      "  libavformat    58. 29.100 / 58. 29.100\n",
      "  libavdevice    58.  8.100 / 58.  8.100\n",
      "  libavfilter     7. 57.100 /  7. 57.100\n",
      "  libswscale      5.  5.100 /  5.  5.100\n",
      "  libswresample   3.  5.100 /  3.  5.100\n",
      "  libpostproc    55.  5.100 / 55.  5.100\n",
      "Input #0, image2, from 'output/unetsegment_checkpoint_%d.png':\n",
      "  Duration: 00:00:10.20, start: 0.000000, bitrate: N/A\n",
      "    Stream #0:0: Video: png, rgba(pc), 1024x512 [SAR 3937:3937 DAR 2:1], 5 fps, 5 tbr, 5 tbn, 5 tbc\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (png (native) -> h264 (libx264))\n",
      "Press [q] to stop, [?] for help\n",
      "[libx264 @ 00000260e3bedd40] using SAR=1/1\n",
      "[libx264 @ 00000260e3bedd40] using cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
      "[libx264 @ 00000260e3bedd40] profile High, level 3.1, 4:2:0, 8-bit\n",
      "[libx264 @ 00000260e3bedd40] 264 - core 160 - H.264/MPEG-4 AVC codec - Copyleft 2003-2020 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=0.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=0 threads=16 lookahead_threads=2 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=5 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=13.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to 'output/video_231125_145716.mp4':\n",
      "  Metadata:\n",
      "    encoder         : Lavf58.29.100\n",
      "    Stream #0:0: Video: h264 (libx264) (avc1 / 0x31637661), yuv420p, 1024x512 [SAR 1:1 DAR 2:1], q=-1--1, 5 fps, 10240 tbn, 5 tbc\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.54.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: -1\n",
      "frame=   51 fps=0.0 q=-1.0 Lsize=    3179kB time=00:00:09.60 bitrate=2713.0kbits/s speed=25.4x    \n",
      "video:3178kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.040685%\n",
      "[libx264 @ 00000260e3bedd40] frame I:3     Avg QP: 8.22  size: 86485\n",
      "[libx264 @ 00000260e3bedd40] frame P:35    Avg QP: 8.85  size: 62439\n",
      "[libx264 @ 00000260e3bedd40] frame B:13    Avg QP: 9.00  size: 62214\n",
      "[libx264 @ 00000260e3bedd40] consecutive B-frames: 56.9% 27.5%  0.0% 15.7%\n",
      "[libx264 @ 00000260e3bedd40] mb I  I16..4: 23.0% 47.9% 29.1%\n",
      "[libx264 @ 00000260e3bedd40] mb P  I16..4: 23.8% 43.1% 25.6%  P16..4:  2.6%  3.3%  1.6%  0.0%  0.0%    skip: 0.1%\n",
      "[libx264 @ 00000260e3bedd40] mb B  I16..4: 22.6% 30.8% 25.9%  B16..8:  4.5%  5.8%  2.9%  direct: 7.5%  skip: 0.0%  L0:41.8% L1:30.7% BI:27.6%\n",
      "[libx264 @ 00000260e3bedd40] 8x8 transform intra:44.9% inter:86.9%\n",
      "[libx264 @ 00000260e3bedd40] coded y,uvDC,uvAC intra: 92.6% 95.8% 94.6% inter: 95.2% 99.1% 92.3%\n",
      "[libx264 @ 00000260e3bedd40] i16 v,h,dc,p: 41% 41% 15%  4%\n",
      "[libx264 @ 00000260e3bedd40] i8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 23% 42% 13%  3%  3%  3%  5%  3%  5%\n",
      "[libx264 @ 00000260e3bedd40] i4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 38% 39%  9%  3%  3%  2%  3%  2%  2%\n",
      "[libx264 @ 00000260e3bedd40] i8c dc,h,v,p: 33% 39% 17% 11%\n",
      "[libx264 @ 00000260e3bedd40] Weighted P-Frames: Y:68.6% UV:68.6%\n",
      "[libx264 @ 00000260e3bedd40] ref P L0: 39.8% 14.1% 19.0% 17.6%  9.6%\n",
      "[libx264 @ 00000260e3bedd40] ref B L0: 65.0% 29.6%  5.4%\n",
      "[libx264 @ 00000260e3bedd40] ref B L1: 86.3% 13.7%\n",
      "[libx264 @ 00000260e3bedd40] kb/s:2551.85\n"
     ]
    }
   ],
   "source": [
    "! ffmpeg -y -f image2 -framerate 5 -i \"output/unetsegment_checkpoint_%d.png\" -c:v libx264 -pix_fmt yuv420p -crf 13 -x264-params psy-rd=0 output/video_{datetime.now().strftime(r\"%y%m%d_%H%M%S\")}.mp4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
